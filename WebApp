# --- BEN√ñTIGTE BIBLIOTHEKEN IMPORTIEREN ---
import streamlit as st
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_ollama import OllamaLLM
from langchain.chains import create_history_aware_retriever, create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import AIMessage, HumanMessage
from streamlit_local_storage import LocalStorage
from streamlit_mic_recorder import mic_recorder
import langchain
from gtts import gTTS
import base64
import io
import os
import re

# --- DEBUG-MODUS F√úR LANGCHAIN ---
# Aktiviert ausf√ºhrliche Log-Ausgaben von LangChain, was bei der Fehlersuche hilft.
langchain.debug = True


# --- STREAMLIT SEITENKONFIGURATION ---
# Richtet die grundlegenden Einstellungen der Webseite ein, wie den Titel im Browser-Tab und das Layout.
st.set_page_config(page_title="Alltags-Assistent", page_icon="ü§ñ", layout="wide")

# --- INITIALISIERUNG DES BROWSER-SPEICHERS ---
# Erstellt ein Objekt, um Daten im Local Storage des Webbrowsers zu speichern und zu laden.
localS = LocalStorage()

# --- FUNKTIONEN ZUM LADEN VON DATEIEN ---
# Die Annotation @st.cache_data sorgt daf√ºr, dass Streamlit das Ergebnis dieser Funktion zwischenspeichert.
# Die Funktion wird nur dann erneut ausgef√ºhrt, wenn sich der Dateipfad √§ndert. Das spart Ladezeit.
@st.cache_data
def get_file_content(filepath):
    # Versucht, eine Textdatei zu √∂ffnen, ihren Inhalt zu lesen und zur√ºckzugeben.
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return f.read()
    # Falls die Datei nicht gefunden wird, wird None zur√ºckgegeben.
    except FileNotFoundError:
        return None

# Diese Funktion wird ebenfalls zwischengespeichert, um die Performance zu verbessern.
@st.cache_data
def load_checklist_items(filepath):
    # Versucht, eine Datei zu √∂ffnen und jede Zeile als einzelnen Eintrag in einer Liste zu speichern.
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            # Leere Zeilen oder Zeilen mit nur Leerzeichen werden ignoriert.
            return [line.strip() for line in f if line.strip()]
    # Falls die Datei nicht gefunden wird, wird eine leere Liste zur√ºckgegeben.
    except FileNotFoundError:
        return []

# --- TTS & LANGCHAIN-SETUP ---
# Funktion zur Umwandlung von Text in gesprochene Audio-Daten.
def text_to_audio_base64(text):
    try:
        # Erstellt ein gTTS-Objekt f√ºr deutschen Text.
        tts = gTTS(text=text, lang='de')
        # Erstellt ein "virtuelles" Dateiobjekt im Arbeitsspeicher.
        audio_fp = io.BytesIO()
        # Schreibt die generierten Audiodaten in das virtuelle Objekt.
        tts.write_to_fp(audio_fp)
        # Setzt den Lesezeiger an den Anfang der virtuellen Datei.
        audio_fp.seek(0)
        # Gibt die rohen Audiodaten zur√ºck.
        return audio_fp.getvalue()
    # F√§ngt m√∂gliche Fehler bei der Audioerstellung ab und zeigt eine Fehlermeldung an.
    except Exception as e:
        st.error(f"Fehler bei der Audio-Erstellung: {e}")
        return None

# @st.cache_resource wird f√ºr Dinge verwendet, die teuer in der Erstellung sind (z.B. Modelle laden, DB-Verbindungen).
# Das Ergebnis wird zwischengespeichert und √ºber verschiedene Sitzungen hinweg wiederverwendet.
@st.cache_resource
def setup_intelligent_chain():
    # Initialisiert das Sprachmodell (LLM), das √ºber Ollama auf einem lokalen Server l√§uft.
    llm = OllamaLLM(model="gpt-oss:20B", base_url="http://127.0.0.1:11434")
    # L√§dt das Embedding-Modell von HuggingFace, das auf der CPU laufen soll.
    embedding = HuggingFaceEmbeddings(model_name="Qwen/Qwen3-Embedding-4B", model_kwargs={"device": "cpu"})
    # Verbindet sich mit der lokalen Chroma Vektor-Datenbank, die die Embeddings enth√§lt.
    db = Chroma(persist_directory="./chroma_db_kombiniert3", embedding_function=embedding)
    # Erstellt einen "Retriever", der die 5 relevantesten Dokumente aus der Datenbank abrufen kann.
    retriever = db.as_retriever(search_kwargs={'k': 5})
    # Gibt das initialisierte Modell und den Retriever zur√ºck.
    return llm, retriever

# Ruft die Setup-Funktion auf und speichert die Ergebnisse in globalen Variablen.
llm, retriever = setup_intelligent_chain()

# Hauptfunktion, die eine Anfrage verarbeitet und eine kontextbezogene Antwort generiert.
def get_conversational_response(frage, chat_history, language_preference, user_context):
    # System-Anweisung f√ºr das LLM, um eine Folgefrage basierend auf dem Chatverlauf und Benutzerfakten umzuformulieren.
    # Ziel ist es, eine eigenst√§ndige Frage zu erstellen, die ohne den vorherigen Kontext verst√§ndlich ist.
    contextualize_q_system_prompt = """Gegeben ist ein Chat-Verlauf, eine Sammlung von Fakten √ºber den Benutzer ({user_context}) und eine neue Frage.
Formuliere basierend auf dem Chat-Verlauf UND den Fakten eine eigenst√§ndige Frage, die ohne den restlichen Chat-Verlauf verst√§ndlich ist.
Antworte NICHT auf die Frage, sondern formuliere sie nur neu. Wenn die Frage bereits eigenst√§ndig ist und keinen Kontext ben√∂tigt, gib sie unver√§ndert zur√ºck."""

    # Erstellt eine Prompt-Vorlage, die die System-Anweisung, den Chat-Verlauf und die neue Benutzereingabe kombiniert.
    contextualize_q_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", contextualize_q_system_prompt),
            MessagesPlaceholder("chat_history"), # Platzhalter f√ºr den bisherigen Chatverlauf
            ("human", "{input}"), # Platzhalter f√ºr die aktuelle Frage des Nutzers
        ]
    )
    # Erstellt einen "history-aware retriever", der zuerst die Frage umformuliert und dann relevante Dokumente sucht.
    history_aware_retriever = create_history_aware_retriever(llm, retriever, contextualize_q_prompt)
    
    # Definiert zwei verschiedene System-Anweisungen f√ºr die endg√ºltige Antwortgenerierung.
    simple_prompt = "Du bist ein freundlicher Alltags-Assistent f√ºr junge Menschen mit Lernschwierigkeiten. Antworte IMMER in **sehr einfacher Sprache**. Benutze kurze S√§tze. Antworte auf die Frage des Nutzers basierend auf dem folgenden Kontext:\n\nKONTEXT:\n{context}"
    standard_prompt = "Du bist ein freundlicher und hilfreicher Alltags-Assistent. Antworte auf die Frage des Nutzers basierend auf dem folgenden Kontext:\n\nKONTEXT:\n{context}"
    
    # Erstellt die endg√ºltige Prompt-Vorlage f√ºr die Frage-Antwort-Kette.
    # W√§hlt die Anweisung basierend auf der vom Benutzer gew√§hlten Spracheinstellung ('simple' oder 'standard').
    qa_prompt = ChatPromptTemplate.from_messages(
        [("system", simple_prompt if language_preference == 'simple' else standard_prompt), MessagesPlaceholder("chat_history"), ("human", "{input}")]
    )
    
    # Erstellt eine Kette, die die abgerufenen Dokumente (den Kontext) in die Prompt-Vorlage einf√ºgt ("stuffing").
    question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)
    # Kombiniert den Retriever und die Frage-Antwort-Kette zu einer vollst√§ndigen RAG (Retrieval-Augmented Generation) Kette.
    rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)
    
    # Zeigt eine Ladeanimation an, w√§hrend das Modell die Antwort generiert.
    with st.spinner("Ich denke nach..."):
        # F√ºhrt die gesamte Kette aus und gibt nur den Text der Antwort zur√ºck.
        return rag_chain.invoke({"input": frage, "chat_history": chat_history, "user_context": user_context})['answer']

# --- SESSION STATE INITIALISIERUNG ---
# Der "Session State" ist der Speicher f√ºr eine einzelne Benutzersitzung. Er merkt sich Werte, solange der Browser-Tab offen ist.
# Wenn der Chat-Verlauf ("messages") noch nicht existiert, wird er als leere Liste initialisiert.
if "messages" not in st.session_state:
    st.session_state.messages = []
# Initialisiert die Spracheinstellung, falls noch nicht vorhanden.
if "language_preference" not in st.session_state:
    st.session_state.language_preference = None
# Initialisiert den Zustand der Checklisten. Versucht zuerst, ihn aus dem Browser-Speicher zu laden.
if "checklist_states" not in st.session_state:
    st.session_state.checklist_states = localS.getItem("all_checklists") or {}
# Initialisiert eine Variable, die steuert, ob der "Ablaufplan"-Button angezeigt wird.
if "show_ablaufplan_button" not in st.session_state:
    st.session_state.show_ablaufplan_button = False
# Initialisiert die Liste der freigeschalteten Checklisten. L√§dt sie aus dem Browser-Speicher.
if "unlocked_checklists" not in st.session_state:
    st.session_state.unlocked_checklists = localS.getItem("unlocked_checklists") or []
# Initialisiert den Zustand der Konversation, z.B. um auf eine spezifische Antwort zu warten.
if "conversation_state" not in st.session_state:
    st.session_state.conversation_state = "chat_active"
# Initialisiert den Benutzerkontext (z.B. Wohnort), der w√§hrend des Gespr√§chs gesammelt wird.
if "context" not in st.session_state:
    st.session_state.context = {}
# Initialisiert eine Variable f√ºr den Text aus der Spracheingabe.
if "voice_prompt" not in st.session_state:
    st.session_state.voice_prompt = None

# Hilfsfunktion, um eine neue Nachricht zum Chat-Verlauf im Session State hinzuzuf√ºgen.
def add_message(role, content):
    st.session_state.messages.append({"role": role, "content": content})

# ======================================================================
# --- SEITENLEISTE (Sidebar) mit Navigation und Checklisten ---
# ======================================================================
st.sidebar.title("Navigation")
# Erstellt einen Button in der Seitenleiste, um das Gespr√§ch zur√ºckzusetzen.
if st.sidebar.button("Neues Gespr√§ch starten üè†", use_container_width=True):
    # Setzt alle relevanten Session-State-Variablen auf ihre Anfangswerte zur√ºck.
    st.session_state.messages = []
    st.session_state.language_preference = None
    st.session_state.show_ablaufplan_button = False
    st.session_state.conversation_state = "chat_active"
    st.session_state.context = {}
    # L√§dt die Seite neu, damit die √Ñnderungen wirksam werden.
    st.rerun()

# Erstellt einen Button, der alles zur√ºcksetzt, inklusive der im Browser gespeicherten Daten.
if st.sidebar.button("Alles zur√ºcksetzen ‚ö†Ô∏è", use_container_width=True, help="L√∂scht den Chat UND die gespeicherten Checklisten."):
    # L√∂scht die Daten aus dem Local Storage.
    localS.setItem("unlocked_checklists", [], key="reset_unlocked_lists")
    localS.setItem("all_checklists", {}, key="reset_all_checklists")
    # L√∂scht alle Schl√ºssel aus dem Session State, um einen kompletten Neustart zu erzwingen.
    for key in list(st.session_state.keys()):
        del st.session_state[key]
    # L√§dt die Seite neu.
    st.rerun()

st.sidebar.divider() # F√ºgt eine Trennlinie in der Seitenleiste hinzu.
st.sidebar.title("‚úÖ Deine Checklisten")

# Ein W√∂rterbuch, das den internen IDs der Checklisten benutzerfreundliche Namen zuordnet.
available_checklists = {"fuehrerschein": "F√ºhrerschein üöó"}

# Wenn noch keine Checklisten freigeschaltet wurden, wird ein Hinweistext angezeigt.
if not st.session_state.unlocked_checklists:
    st.sidebar.info("Deine pers√∂nlichen Checklisten erscheinen hier, sobald du sie im Chat entdeckt hast.")

# Geht durch alle freigeschalteten Checklisten-IDs.
for checklist_id in st.session_state.unlocked_checklists:
    # Holt den Anzeigenamen aus dem W√∂rterbuch.
    display_name = available_checklists.get(checklist_id, "Unbekannte Checkliste")
    # Erstellt einen ausklappbaren Bereich (Expander) f√ºr jede Checkliste.
    with st.sidebar.expander(display_name, expanded=True):
        # L√§dt die Eintr√§ge f√ºr die aktuelle Checkliste aus der entsprechenden Textdatei.
        items = load_checklist_items(os.path.join("Ablaufplaene", f"checklist_{checklist_id}.txt"))
        
        # Wenn Eintr√§ge gefunden wurden:
        if items:
            # Stellt sicher, dass ein Speicherbereich f√ºr diese Checkliste im Session State existiert.
            if checklist_id not in st.session_state.checklist_states:
                st.session_state.checklist_states[checklist_id] = {}
            # Holt den aktuellen Zustand der Checkboxen f√ºr diese Liste.
            current_states = st.session_state.checklist_states[checklist_id]
            all_checked = True # Variable, um zu pr√ºfen, ob alles abgehakt ist.
            # Geht jeden Eintrag der Checkliste durch.
            for item in items:
                # Initialisiert den Zustand des Eintrags als "nicht abgehakt", falls er neu ist.
                if item not in current_states:
                    current_states[item] = False
                # Erstellt eine Checkbox. Der `key` muss eindeutig sein, um Fehler zu vermeiden.
                is_checked = st.checkbox(item, value=current_states.get(item, False), key=f"sidebar_check_{checklist_id}_{item}")
                # Speichert den neuen Zustand der Checkbox.
                current_states[item] = is_checked
                # Wenn auch nur eine Checkbox nicht abgehakt ist, wird die Variable auf False gesetzt.
                if not is_checked:
                    all_checked = False
            # Wenn alle Eintr√§ge abgehakt sind und die Liste nicht leer war, wird eine Erfolgsmeldung angezeigt.
            if all_checked and items:
                st.success("Super! Alles erledigt! üéâ")

# Speichert den aktuellen Zustand aller Checklisten und der freigeschalteten Listen im Browser-Speicher.
localS.setItem("all_checklists", st.session_state.checklist_states, key="storage_checklist_states")
localS.setItem("unlocked_checklists", st.session_state.unlocked_checklists, key="storage_unlocked_lists")

# ======================================================================
# --- Haupt-Chat-Interface ---
# ======================================================================
st.title("Dein pers√∂nlicher Alltags-Assistent ü§ñ")

# --- STARTLOGIK ---
# Diese Logik wird nur ausgef√ºhrt, wenn der Chat leer ist (also zu Beginn).
if not st.session_state.messages:
    # Schritt 1: Wenn die Sprache noch nicht gew√§hlt wurde, frage danach.
    if st.session_state.language_preference is None:
        with st.chat_message("assistant"):
            st.markdown("Hallo! üëã Bevor wir beginnen: Soll ich dir in **einfacher Sprache** antworten?")
            cols = st.columns(2) # Erstellt zwei Spalten f√ºr die Buttons.
            # Button f√ºr einfache Sprache
            if cols[0].button("Ja, in einfacher Sprache", use_container_width=True):
                st.session_state.language_preference = 'simple'
                st.rerun() # L√§dt die Seite neu, um zum n√§chsten Schritt zu gelangen.
            # Button f√ºr Standardsprache
            if cols[1].button("Nein, danke", use_container_width=True):
                st.session_state.language_preference = 'standard'
                st.rerun()
    # Schritt 2: Wenn die Sprache gew√§hlt wurde, zeige die Themen-Buttons an.
    else:
        with st.chat_message("assistant"):
            st.markdown("Verstanden. Womit kann ich dir helfen?")
            cols = st.columns(3) # Erstellt drei Spalten f√ºr die Themen.
            # Button f√ºr das Thema "F√ºhrerschein"
            if cols[0].button("F√ºhrerschein üöó", use_container_width=True):
                add_message("user", "Ich interessiere mich f√ºr den F√ºhrerschein.")
                # L√§dt den Einf√ºhrungstext aus einer Datei.
                einfuehrung_text = get_file_content(os.path.join("Einfuehrungstexte", "Einfuehrung_Fuehrerschein.txt"))
                add_message("assistant", einfuehrung_text or "Text nicht gefunden.")
                st.session_state.show_ablaufplan_button = True # Aktiviert den Button f√ºr den Ablaufplan.
                st.rerun()
            # Button f√ºr das Thema "Girokonto"
            if cols[1].button("Girokonto üí≥", use_container_width=True):
                add_message("user", "Ich interessiere mich f√ºr das Girokonto.")
                einfuehrung_text = get_file_content(os.path.join("Einfuehrungstexte", "Einfuehrung_Girokonto.txt"))
                add_message("assistant", einfuehrung_text or "Text nicht gefunden.")
                st.rerun()
            # Button f√ºr das Thema "Freizeit"
            if cols[2].button("Freizeit ‚öΩÔ∏è", use_container_width=True):
                add_message("user", "Ich interessiere mich f√ºr Freizeitaktivit√§ten.")
                einfuehrung_text = get_file_content(os.path.join("Einfuehrungstexte", "Einfuehrung_Freizeit.txt"))
                add_message("assistant", einfuehrung_text or "Text nicht gefunden.")
                st.rerun()

# --- CHAT-VERLAUF ANZEIGEN ---
# Geht durch alle Nachrichten im Session State und zeigt sie an.
for i, message in enumerate(st.session_state.messages):
    with st.chat_message(message["role"]): # Erstellt eine Chat-Blase f√ºr "user" oder "assistant".
        st.markdown(message["content"]) # Zeigt den Inhalt der Nachricht an.
        # Nur bei Nachrichten des Assistenten wird ein Vorlese-Button hinzugef√ºgt.
        if message["role"] == "assistant":
            _, col_btn = st.columns([0.95, 0.05]) # Erstellt Spalten, um den Button rechts zu platzieren.
            with col_btn:
                # Erstellt den Vorlese-Button mit einem eindeutigen Schl√ºssel.
                if st.button("üîä", key=f"tts_button_{i}", help="Vorlesen"):
                    # Wandelt den Nachrichtentext in Audio um.
                    audio_bytes = text_to_audio_base64(message["content"])
                    # Wenn die Audio-Erstellung erfolgreich war, wird ein Audio-Player angezeigt und automatisch gestartet.
                    if audio_bytes:
                        st.audio(audio_bytes, format="audio/mp3", autoplay=True)

# --- BUTTON F√úR ABLAUFPLAN ---
# Zeigt diesen Button nur an, wenn die entsprechende Variable im Session State True ist.
if st.session_state.get("show_ablaufplan_button", False):
    if st.button("Ablaufplan F√ºhrerschein anzeigen", use_container_width=True):
        # F√ºgt die Aktionen des Nutzers und des Assistenten zum Chatverlauf hinzu.
        add_message("user", "Zeig mir bitte den Ablaufplan f√ºr den F√ºhrerschein.")
        ablaufplan_text = get_file_content(os.path.join("Ablaufplaene", "Ablaufplan_Fuehrerschein.txt"))
        if ablaufplan_text:
            add_message("assistant", ablaufplan_text)
            # Zeigt einen permanenten Hinweis (Info-Box) an.
            st.info("Tipp: Die interaktive Checkliste dazu findest du ab jetzt in der Seitenleiste links! üëà", icon="üí°")
            
            # Schaltet die F√ºhrerschein-Checkliste f√ºr die Seitenleiste frei, falls noch nicht geschehen.
            if "fuehrerschein" not in st.session_state.unlocked_checklists:
                st.session_state.unlocked_checklists.append("fuehrerschein")
        else:
            add_message("assistant", "Entschuldigung, den Ablaufplan habe ich nicht gefunden.")
        # Versteckt den Button nach dem Klick, um doppelte Anzeigen zu vermeiden.
        st.session_state.show_ablaufplan_button = False
        st.rerun()


# --- HAUPTLOGIK F√úR DEN CHAT-INPUT ---
# Teilt den unteren Bereich in zwei Spalten: eine f√ºr das Textfeld, eine f√ºr den Mikrofon-Button.
input_col, mic_col = st.columns([0.9, 0.1])

with input_col:
    # Erstellt das Texteingabefeld am unteren Rand der Seite.
    text_prompt = st.chat_input("Stelle eine Frage oder w√§hle ein Thema...")

with mic_col:
    st.text("") # F√ºgt einen kleinen Abstand hinzu, um den Button vertikal zu zentrieren.
    # Initialisiert die Mikrofon-Recorder-Komponente.
    voice_recording = mic_recorder(
        start_prompt="üé§", # Symbol f√ºr den Start der Aufnahme
        stop_prompt="üõë",  # Symbol f√ºr das Stoppen der Aufnahme
        key='recorder',
        use_container_width=True
    )

# Wenn eine Sprachaufnahme gemacht und in Text umgewandelt wurde, speichere den Text im Session State.
if voice_recording and voice_recording.get('text'):
    st.session_state.voice_prompt = voice_recording['text']

# Entscheidet, welche Eingabe verwendet wird. Die Texteingabe hat Vorrang.
prompt = text_prompt or st.session_state.voice_prompt

# Wenn eine Eingabe (entweder Text oder Sprache) vorhanden ist, wird dieser Block ausgef√ºhrt.
if prompt:
    # Setzt die Spracheingabe zur√ºck, damit sie nicht erneut verarbeitet wird.
    st.session_state.voice_prompt = None
    
    # Versteckt den Ablaufplan-Button, da der Nutzer eine neue Frage gestellt hat.
    st.session_state.show_ablaufplan_button = False
    # F√ºgt die Nachricht des Nutzers zum Chatverlauf hinzu.
    add_message("user", prompt)
    
    # Bereitet den Chat-Verlauf f√ºr LangChain vor, indem er in das richtige Format (AIMessage, HumanMessage) gebracht wird.
    # Die letzte Nachricht (die aktuelle des Nutzers) wird weggelassen.
    chat_history = [AIMessage(content=m['content']) if m['role']=='assistant' else HumanMessage(content=m['content']) for m in st.session_state.messages[:-1]]

    # Sucht mit einem regul√§ren Ausdruck nach einem Ortsnamen in der Nutzereingabe (z.B. "in Berlin").
    location_match = re.search(r'\b(in|bei|nahe)\s+([A-Z][a-z√§√∂√º√ü]+)\b', prompt)
    # Wenn ein Ort gefunden wurde und noch kein Wohnort im Kontext gespeichert ist:
    if location_match and "wohnort" not in st.session_state.context:
        stadt = location_match.group(2) # Extrahiert den Namen der Stadt.
        st.session_state.context["wohnort"] = stadt # Speichert die Stadt im Kontext.
        st.toast(f"Ich merke mir {stadt} als deinen Wohnort f√ºr dieses Gespr√§ch.") # Zeigt eine kurze Best√§tigung an.

    # Baut einen String mit allen bekannten Fakten √ºber den Benutzer zusammen.
    context_parts = []
    if "klasse" in st.session_state.context:
        context_parts.append(f"F√ºhrerscheinklasse: {st.session_state.context['klasse']}")
    if "wohnort" in st.session_state.context:
        context_parts.append(f"Wohnort: {st.session_state.context['wohnort']}")
    user_context_string = ", ".join(context_parts) if context_parts else "keine zus√§tzlichen Fakten"

    # Setzt die Frage, die an die KI gesendet wird, standardm√§√üig auf die Benutzereingabe.
    frage_fuer_ki = prompt
    
    # --- Logik f√ºr mehrstufige Konversationen (Beispiel: F√ºhrerscheinkosten) ---
    # Wenn der Bot auf die Angabe der F√ºhrerscheinklasse wartet:
    if st.session_state.conversation_state == "awaiting_klasse_for_price":
        st.session_state.context["klasse"] = prompt.upper() # Speichert die Klasse im Kontext.
        st.session_state.conversation_state = "chat_active" # Setzt den Zustand zur√ºck.
        # Formuliert die urspr√ºngliche Frage neu mit der jetzt bekannten Klasse.
        frage_fuer_ki = f"Was kostet der F√ºhrerschein der Klasse {st.session_state.context['klasse']}?"
        
    # Wenn der Nutzer nach Kosten f√ºr den F√ºhrerschein fragt, aber keine Klasse nennt:
    elif ("preis" in prompt.lower() or "kosten" in prompt.lower() or "kostet" in prompt.lower()) and "f√ºhrerschein" in prompt.lower() and "klasse" not in st.session_state.context:
        st.session_state.conversation_state = "awaiting_klasse_for_price" # Setzt den Zustand auf "warten".
        # Stellt eine R√ºckfrage.
        antwort_text = "Gerne! Um dir eine genaue Auskunft geben zu k√∂nnen: F√ºr welche F√ºhrerscheinklasse interessierst du dich denn? (z.B. **B** f√ºr Auto, **A** f√ºr Motorrad oder **AM** f√ºr Roller)"
        add_message("assistant", antwort_text)
        st.rerun() # L√§dt die Seite neu, um die R√ºckfrage sofort anzuzeigen und auf die Antwort zu warten.
    else:
        # Ruft die Hauptfunktion auf, um die Antwort von der KI zu erhalten, wenn keine R√ºckfrage n√∂tig ist.
        antwort = get_conversational_response(
            frage=frage_fuer_ki, 
            chat_history=chat_history, 
            language_preference=st.session_state.language_preference,
            user_context=user_context_string
        )
        # F√ºgt die Antwort der KI zum Chatverlauf hinzu.
        add_message("assistant", antwort)
            
        # L√§dt die Seite neu, um den kompletten neuen Chatverlauf anzuzeigen.
        st.rerun()
